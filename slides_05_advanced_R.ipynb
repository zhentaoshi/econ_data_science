{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89624571",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced R\n",
    "\n",
    "Zhentao Shi\n",
    "\n",
    "<!-- code is tested on SCRP -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b37e255",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "* Efficient computation in R.\n",
    "\n",
    "* R is a vector-oriented language. In most cases, vectorization speeds up computation.\n",
    "* Multiple CPUs for parallel execution to save time after optimizing the code for speed.\n",
    "\n",
    "* Cloud computing: Communicating with a remote cluster is different from operating a local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f4d14",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Vectorization\n",
    "\n",
    "Despite mathematical equivalence, various ways of calculation can perform distinctively in terms of computational speed.\n",
    "\n",
    "Does computational speed matter?\n",
    "\n",
    "For a job that takes less than a minutes, the time difference is not a big deal.\n",
    "But sometimes economic problems can be clumsy. For structural estimation commonly seen in industrial organization, a single estimation can take up to a week. \n",
    "In econometrics, other computational intensive procedures include bootstrap, simulated maximum likelihood and simulated method of moments. Even if a single execution does not take much time, repeating such a procedure for thousands of replications will consume a non-trivial duration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ac1eb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Moreover, machine learning methods that crunch \n",
    "big data usually involve tuning parameters, so the same procedure must be carried out\n",
    "at each point of a grid of tuning parameters. \n",
    "For example, the preferred algorithm in @lin2020 takes 8 hours on a 24-core remote server to find out \n",
    "the best combination of tuning parameters.\n",
    "For those problems, code optimization is essential.\n",
    "\n",
    "Of course, optimizing code takes human time. It is a balance of human time and machine time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c9ba9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "In OLS regression, under homoskedasticity\n",
    "\n",
    "$$\n",
    "\\sqrt{n}\\left(\\widehat{\\beta}-\\beta_{0}\\right)\\stackrel{d}{\\to}N\\left(0,\\sigma^{2}\\left(E\\left[x_{i}x_{i}'\\right]\\right)^{-1}\\right)\n",
    "$$\n",
    "\n",
    "where the asymptotic variance can be consistently estimated by \n",
    "$(X'X)^{-1} \\sum_{i=1}^n \\widehat{e}^{2}$. However, under heteroskedasticity\n",
    "\n",
    "$$\n",
    "\\sqrt{n}\\left(\\widehat{\\beta}-\\beta_{0}\\right)\\stackrel{d}{\\to}N\\left(0,E\\left[x_{i}x_{i}'\\right]^{-1}\\mathrm{var}\\left(x_{i}e_{i}\\right)E\\left[x_{i}x_{i}'\\right]^{-1}\\right)\n",
    "$$\n",
    "\n",
    "where $\\mathrm{var}\\left(x_{i}e_{i}\\right)$ can be estimated by \n",
    "\n",
    "$$\n",
    "\\underset{\\mathrm{opt1}}{\\frac{1}{n}\\sum_{i=1}^{n}x_{i}x_{i}'\\widehat{e}_{i}^{2}}=\\underset{\\mathrm{opt2,3}}{\\frac{1}{n}X'DX}=\\underset{\\mathrm{opt 4}}{\\frac{1}{n}\\left(X'D^{1/2}\\right)\\left(D^{1/2}X\\right)}\n",
    "$$\n",
    "\n",
    "where $D$ is a diagonal matrix of $\\left(\\widehat{\\epsilon}_{1}^{2},\\widehat{\\epsilon}_{2,}^{2},\\ldots,\\widehat{\\epsilon}_{n}^{2}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8864161f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are at least 4 mathematically equivalent ways to compute the \"meat\" of the sandwich form.\n",
    "\n",
    "1. literally sum $\\hat{e}_i^2 x_i x_i'$  over $i=1,\\ldots,n$ one by one.\n",
    "2. $X' \\mathrm{diag}(\\hat{e}^2) X$, with a dense central matrix.\n",
    "3. $X' \\mathrm{diag}(\\hat{e}^2) X$, with a sparse central matrix.\n",
    "4. Do cross product to `X*e_hat`. It takes advantage of the element-by-element operation in R.\n",
    "\n",
    "\n",
    "It takes advantage of the element-by-element operation in R.\n",
    "We first generate the data of binary response and regressors. Due to the discrete nature of the dependent variable, the error term in the linear probability model is heteroskedastic. It is necessary to use the heteroskedastic-robust variance to consistently estimate the asymptotic variance of the OLS estimator. The code chunk below estimates the coefficients and obtains the residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3575646c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# an example of robust variance matrix.\n",
    "# compare the implementation via matrix, Matrix (package) and vecteroization.\n",
    "\n",
    "# n = 5000; Rep = 10; # Matrix is quick, matrix is slow, adding is OK\n",
    "\n",
    "source(\"data_example/lec2.R\")\n",
    "\n",
    "n <- 50\n",
    "Rep <- 1000 \n",
    "\n",
    "data.Xe <- lpm(n) # see the function in \"data_example/lec2.R\"\n",
    "X <- data.Xe$X\n",
    "e_hat <- data.Xe$e_hat\n",
    "\n",
    "XXe2 <- matrix(0, nrow = 2, ncol = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58848e36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We run the 4 estimators for the same data, and compare the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "125391cc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 50 , Rep = 1000 , opt = 1 , time = 0.2992959 \n",
      "n = 50 , Rep = 1000 , opt = 2 , time = 0.07965302 \n",
      "n = 50 , Rep = 1000 , opt = 3 , time = 3.100327 \n",
      "n = 50 , Rep = 1000 , opt = 4 , time = 0.03528619 \n"
     ]
    }
   ],
   "source": [
    "for (opt in 1:4) {\n",
    "  pts0 <- Sys.time()\n",
    "\n",
    "  for (iter in 1:Rep) {\n",
    "    set.seed(iter) # to make sure that the data used\n",
    "    # different estimation methods are the same\n",
    "\n",
    "\n",
    "    if (opt == 1) {\n",
    "      for (i in 1:n) {\n",
    "        XXe2 <- XXe2 + e_hat[i]^2 * X[i, ] %*% t(X[i, ])\n",
    "      }\n",
    "    } else if (opt == 2) { # the vectorized version with dense matrix\n",
    "      e_hat2_M <- matrix(0, nrow = n, ncol = n)\n",
    "      diag(e_hat2_M) <- e_hat^2\n",
    "      XXe2 <- t(X) %*% e_hat2_M %*% X\n",
    "    } else if (opt == 3) { # the vectorized version with sparse matrix\n",
    "      e_hat2_M <- Matrix::Matrix(0, ncol = n, nrow = n)\n",
    "      diag(e_hat2_M) <- e_hat^2\n",
    "      XXe2 <- t(X) %*% e_hat2_M %*% X\n",
    "    } else if (opt == 4) { # the best vectorization method. No waste\n",
    "      Xe <- X * e_hat\n",
    "      XXe2 <- t(Xe) %*% Xe\n",
    "    }\n",
    "\n",
    "\n",
    "    XX_inv <- solve(t(X) %*% X)\n",
    "    sig_B <- XX_inv %*% XXe2 %*% XX_inv\n",
    "  }\n",
    "  cat(\"n =\", n, \", Rep =\", Rep, \", opt =\", opt, \", time =\", Sys.time() - pts0, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0782a96d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We clearly see the difference in running time, though the 4 methods are mathematically the same.\n",
    "When $n$ is small, `matrix` is fast and `Matrix` is slow; the vectorized version is the fastest.\n",
    "When $n$ is big, `matrix` is slow and `Matrix` is fast; the vectorized version is still the fastest.\n",
    "\n",
    "In this simulation exercise, we repeat the procedure many times to make the time comparison more evident, for a single execution takes very short time in this simple operation. A real-data example is in `data_example/IPUMS.R` with  234 thousand observations, where the time difference is dramatic but the intuitive solution indeed does not take much time. \n",
    "It demonstrates the usefulness of vectorization. Vectorization can \n",
    "significantly saves computing time in more complicated operations, for example, in \n",
    "heteroskedastic and autocorrelation consistent variance estimation (HAC)\n",
    "in econometrics which involves many layers of matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba16a2cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Efficient Loop\n",
    "\n",
    "R was the heir of S, an old language. R evolves with packages that are designed to \n",
    "adapt to new big data environment. Many examples can be found in [[Wickham etc,2016]](https://books.google.com.hk/books/about/R_for_Data_Science.html?id=vfi3DQAAQBAJ&redir_esc=y). \n",
    "Here we introduce [`plyr`](http://plyr.had.co.nz/). \n",
    "\n",
    "In standard `for` loops, we have to do a lot of housekeeping work. [Hadley Wickham](http://had.co.nz/)'s `plyr` simplifies the job and facilitates parallelization.\n",
    "\n",
    "### Example\n",
    "\n",
    "Here we calculate the empirical coverage probability of a Poisson distribution of degrees of freedom 2. We first write a user-defined function `CI` for confidence interval, which was used in the last lecture.\n",
    "\n",
    "This is a standard `for` loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd23d829",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop without pre-definition takes 21.96541 seconds\n",
      "loop with pre-definition takes 8.035712 seconds\n"
     ]
    }
   ],
   "source": [
    "Rep <- 100000\n",
    "sample_size <- 1000\n",
    "mu <- 2\n",
    "\n",
    "source(\"data_example/lec2.R\")\n",
    "# append a new outcome after each loop\n",
    "pts0 <- Sys.time() # check time\n",
    "for (i in 1:Rep) {\n",
    "  x <- rpois(sample_size, mu)\n",
    "  bounds <- CI(x)\n",
    "  out_i <- ((bounds$lower <= mu) & (mu <= bounds$upper))\n",
    "  if (i == 1) {\n",
    "    out <- out_i\n",
    "  } else {\n",
    "    out <- c(out, out_i)\n",
    "  }\n",
    "}\n",
    "\n",
    "pts1 <- Sys.time() - pts0 # check time elapse\n",
    "cat(\"loop without pre-definition takes\", pts1, \"seconds\\n\")\n",
    "\n",
    "\n",
    "# pre-define a container\n",
    "out <- rep(0, Rep)\n",
    "pts0 <- Sys.time() # check time\n",
    "for (i in 1:Rep) {\n",
    "  x <- rpois(sample_size, mu)\n",
    "  bounds <- CI(x)\n",
    "  out[i] <- ((bounds$lower <= mu) & (mu <= bounds$upper))\n",
    "}\n",
    "\n",
    "pts1 <- Sys.time() - pts0 # check time elapse\n",
    "cat(\"loop with pre-definition takes\", pts1, \"seconds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9801994",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pay attention to the line `out = rep(0, Rep)`. It *pre-defines* a vector `out` to be filled by\n",
    "`out[i] = ( ( bounds$lower <= mu  ) & (mu <= bounds$upper) )`. The computer opens a continuous patch of memory for the vector `out`. When new result comes in, the old element is replaced. If we do not pre-define `out`\n",
    "but append one more element in each loop, the length of `out` will change in each replication and\n",
    "every time a new patch of memory will be assigned to store it. The latter approach will spend much more time just to locate the vector in the memory.\n",
    "\n",
    "`out` is the result container. In a `for` loop, we pre-define a container, and replace the elements\n",
    "of the container in each loop by explicitly calling the index.\n",
    "\n",
    "In contrast, a `plyr` loop saves the house keeping chores, and makes it easier to parallelize. In the example below, we encapsulate the chunk in the `for` loop as a new function `capture`, and run the replication via `__ply`.\n",
    "`__ply` is a family of functions. `ldply` here means that the input is a list (`l`) and the output is a data frame (`d`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd86dff7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'plyr' was built under R version 4.2.2\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plyr loop takes 9.296654 seconds\n"
     ]
    }
   ],
   "source": [
    "library(plyr)\n",
    "\n",
    "capture <- function(i) {\n",
    "  x <- rpois(sample_size, mu)\n",
    "  bounds <- CI(x)\n",
    "  return((bounds$lower <= mu) & (mu <= bounds$upper))\n",
    "}\n",
    "\n",
    "pts0 <- Sys.time() # check time\n",
    "out <- ldply(.data = 1:Rep, .fun = capture)\n",
    "\n",
    "pts1 <- Sys.time() - pts0 # check time elapse\n",
    "cat(\"plyr loop takes\", pts1, \"seconds\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41844d77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This example is so simple that the advantage of `plyr` is not dramatic. The difference in coding will be noticeable in complex problems with big data frames.\n",
    "In terms of speed, `plyr` does not run much faster than a `for` loop. They are of similar performance.\n",
    "Parallel computing will be our next topic. It is quite easy to implement parallel execution with `plyr`---we just need to change one argument in the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f31411",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallel Computing\n",
    "\n",
    "Parallel computing becomes essential when the data size is beyond the storage of a single computer, for example  @li2018embracing.\n",
    "Here we explore the speed gain of parallel computing on a multicore machine.\n",
    "\n",
    "Here we introduce how to coordinate multiple cores on a single computer. \n",
    "The packages `foreach` and `doParallel` are useful for parallel computing.\n",
    "Below is the basic structure. `registerDoParallel(number)` prepares a few CPU cores\n",
    "to accept incoming jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867c5def",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "library(plyr); library(foreach); library(doParallel)\n",
    "\n",
    "registerDoParallel(a_number) # opens specified number of CPUs\n",
    "\n",
    "out <- foreach(icount(Rep), .combine = option) %dopar% {\n",
    "  my_expressions\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee65c44a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we have two CPUs running simultaneously, in theory we can cut the time to a half of that on a single CPU. Is that what happening in practice?\n",
    "\n",
    "### Example\n",
    "\n",
    "Compare the speed of a parallel loop and a single-core sequential loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8f380",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "library(foreach)\n",
    "library(doParallel)\n",
    "\n",
    "registerDoParallel(2) # open 2 CPUs\n",
    "\n",
    "pts0 <- Sys.time() # check time\n",
    "\n",
    "out <- foreach(icount(Rep), .combine = c) %dopar% {\n",
    "  capture()\n",
    "}\n",
    "\n",
    "pts1 <- Sys.time() - pts0 # check time elapse\n",
    "cat(\"parallel loop takes\", pts1, \"seconds\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54338eaa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Surprisingly, the above code block of parallel computing runs even more slowly.\n",
    "It is because the task in each loop can be done in very short time.\n",
    "In contrast, the code chunk below will tell a different story.\n",
    "There the time in each loop is non-trivial,\n",
    "and then parallelism dominates the overhead of the CPU communication.\n",
    "The only difference between the two implementations below is \n",
    "that the first uses `%dopar%` and the latter uses `%do%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a185b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Rep <- 200\n",
    "sample_size <- 2000000\n",
    "\n",
    "registerDoParallel(8) # change the number of open CPUs according to\n",
    "# the specification of your computer\n",
    "\n",
    "pts0 <- Sys.time() # check time\n",
    "out <- foreach(icount(Rep), .combine = c) %dopar% {\n",
    "  capture()\n",
    "}\n",
    "\n",
    "cat(\"8-core parallel loop takes\", Sys.time() - pts0 , \"seconds\\n\")\n",
    "\n",
    "pts0 <- Sys.time()\n",
    "out <- foreach(icount(Rep), .combine = c) %do% {\n",
    "  capture()\n",
    "}\n",
    "\n",
    "cat(\"single-core loop takes\", Sys.time() - pts0 , \"seconds\\n\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.0"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "serif"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
